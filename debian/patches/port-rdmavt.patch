Description: Port rdmavt to debian kernel 3.16
 Ports the code delivered for rdmavt_uverbs to debian kernel 3.16.
Author: Brian T. Smith <bsmith@systemfabricworks.com>
Forwarded: not-needed
Last-Update: <2017-12-14>
---
This patch header follows DEP-3: http://dep.debian.net/deps/dep3/
--- a/rdmavt/ah.c
+++ b/rdmavt/ah.c
@@ -120,6 +120,8 @@
 	spin_lock_irqsave(&dev->n_ahs_lock, flags);
 	if (dev->n_ahs_allocated == dev->dparms.props.max_ah) {
 		spin_unlock(&dev->n_ahs_lock);
+		rvt_pr_warn_ratelimited(dev, "%s: too many AHs allocated: max_ahs=%d\n",
+								__func__, dev->dparms.props.max_ah);
 		kfree(ah);
 		return ERR_PTR(-ENOMEM);
 	}
--- a/rdmavt/cq.h
+++ b/rdmavt/cq.h
@@ -51,10 +51,10 @@
 #include <rdma/rdma_vt.h>
 #include <rdma/rdmavt_cq.h>
 
-struct ib_cq *rvt_create_cq(struct ib_device *ibdev,
-			    const struct ib_cq_init_attr *attr,
-			    struct ib_ucontext *context,
-			    struct ib_udata *udata);
+struct ib_cq *rvt_create_cq(struct ib_device *ibdev, int entries,
+							int comp_vector,
+							struct ib_ucontext *context,
+							struct ib_udata *udata);
 int rvt_destroy_cq(struct ib_cq *ibcq);
 int rvt_req_notify_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags notify_flags);
 int rvt_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata);
--- a/rdmavt/mad.c
+++ b/rdmavt/mad.c
@@ -111,7 +111,7 @@
 		agent = ib_register_mad_agent(&rdi->ibdev, p + 1,
 					      IB_QPT_SMI,
 					      NULL, 0, rvt_send_mad_handler,
-					      NULL, NULL, 0);
+					      NULL, NULL);
 		if (IS_ERR(agent)) {
 			ret = PTR_ERR(agent);
 			goto err;
--- a/rdmavt/mcast.c
+++ b/rdmavt/mcast.c
@@ -51,6 +51,7 @@
 #include <rdma/rdma_vt.h>
 #include <rdma/rdmavt_qp.h>
 
+#include "vt.h"
 #include "mcast.h"
 
 /**
@@ -232,6 +233,8 @@
 		}
 		if (tmcast->n_attached ==
 		    rdi->dparms.props.max_mcast_qp_attach) {
+			rvt_pr_warn_ratelimited(rdi, "%s: too many multicast QPs attached: max_mcast_qp_attached=%d\n",
+									__func__, rdi->dparms.props.max_mcast_qp_attach);
 			ret = ENOMEM;
 			goto bail;
 		}
@@ -246,6 +249,8 @@
 	spin_lock(&rdi->n_mcast_grps_lock);
 	if (rdi->n_mcast_grps_allocated == rdi->dparms.props.max_mcast_grp) {
 		spin_unlock(&rdi->n_mcast_grps_lock);
+		rvt_pr_warn_ratelimited(rdi, "%s: too many multicast groups allocated: max_mcast_grps=%d\n",
+								__func__, rdi->dparms.props.max_mcast_grp);
 		ret = ENOMEM;
 		goto bail;
 	}
--- a/rdmavt/mr.c
+++ b/rdmavt/mr.c
@@ -49,6 +49,7 @@
 #include <linux/vmalloc.h>
 #include <rdma/ib_umem.h>
 #include <rdma/rdma_vt.h>
+#include "core_compat.h"
 #include "vt.h"
 #include "mr.h"
 #include "trace.h"
@@ -408,7 +409,7 @@
 	mr->mr.user_base = start;
 	mr->mr.iova = virt_addr;
 	mr->mr.length = length;
-	mr->mr.offset = ib_umem_offset(umem);
+	mr->mr.offset = umem->offset;
 	mr->mr.access_flags = mr_access_flags;
 	mr->umem = umem;
 
@@ -501,9 +502,9 @@
 	timeout = wait_for_completion_timeout(&mr->comp, 5 * HZ);
 	if (!timeout) {
 		rvt_pr_err(rdi,
-			   "%s timeout mr %p pd %p lkey %x refcount %ld\n",
+			   "%s timeout mr %p pd %p lkey %x refcount %d\n",
 			   t, mr, mr->pd, mr->lkey,
-			   atomic_long_read(&mr->refcount.count));
+			   atomic_read(&mr->refcount.count));
 		rvt_get_mr(mr);
 		return -EBUSY;
 	}
@@ -596,6 +597,7 @@
 	return &mr->ibmr;
 }
 
+#ifdef CONFIG_RVT_MAP_MR_SG
 /**
  * rvt_set_page - page assignment function called by ib_sg_to_pages
  * @ibmr: memory region
@@ -647,6 +649,7 @@
 	return ib_sg_to_pages(ibmr, sg, sg_nents, sg_offset,
 			      rvt_set_page);
 }
+#endif /* CONFIG_RVT_MAP_MR_SG */
 
 /**
  * rvt_fast_reg_mr - fast register physical MR
@@ -793,7 +796,7 @@
 	u32 ps;
 	struct rvt_dev_info *rdi = ib_to_rvt(ibfmr->device);
 
-	i = atomic_long_read(&fmr->mr.refcount.count);
+	i = atomic_read(&fmr->mr.refcount.count);
 	if (i > 2)
 		return -EBUSY;
 
--- a/rdmavt/pd.c
+++ b/rdmavt/pd.c
@@ -46,6 +46,7 @@
  */
 
 #include <linux/slab.h>
+#include "vt.h"
 #include "pd.h"
 
 /**
@@ -81,6 +82,8 @@
 	spin_lock(&dev->n_pds_lock);
 	if (dev->n_pds_allocated == dev->dparms.props.max_pd) {
 		spin_unlock(&dev->n_pds_lock);
+		rvt_pr_warn_ratelimited(dev, "%s: too many PDs allocated: max_pds=%d\n",
+								__func__, dev->dparms.props.max_pd);
 		kfree(pd);
 		ret = ERR_PTR(-ENOMEM);
 		goto bail;
--- a/rdmavt/qp.c
+++ b/rdmavt/qp.c
@@ -993,6 +993,7 @@
 	spin_lock(&rdi->n_qps_lock);
 	if (rdi->n_qps_allocated == rdi->dparms.props.max_qp) {
 		spin_unlock(&rdi->n_qps_lock);
+		rvt_pr_warn_ratelimited(rdi, "%s: too many QPs allocated, max_qps=%d\n", __func__, rdi->dparms.props.max_qp);
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_ip;
 	}
--- a/rdmavt/srq.c
+++ b/rdmavt/srq.c
@@ -144,6 +144,8 @@
 	spin_lock(&dev->n_srqs_lock);
 	if (dev->n_srqs_allocated == dev->dparms.props.max_srq) {
 		spin_unlock(&dev->n_srqs_lock);
+		rvt_pr_warn_ratelimited(dev, "%s: too many SRQs allocated, max_srqs=%d\n",
+								__func__, dev->dparms.props.max_srq);
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_ip;
 	}
--- a/rdmavt/vt.c
+++ b/rdmavt/vt.c
@@ -120,13 +120,10 @@
 EXPORT_SYMBOL(rvt_dealloc_device);
 
 static int rvt_query_device(struct ib_device *ibdev,
-			    struct ib_device_attr *props,
-			    struct ib_udata *uhw)
+							struct ib_device_attr *props)
 {
 	struct rvt_dev_info *rdi = ib_to_rvt(ibdev);
 
-	if (uhw->inlen || uhw->outlen)
-		return -EINVAL;
 	/*
 	 * Return rvt_dev_info.dparms.props contents
 	 */
@@ -320,6 +317,7 @@
 	return 0;
 }
 
+#ifdef CONFIG_RVT_GET_PORT_IMMUTABLE
 static int rvt_get_port_immutable(struct ib_device *ibdev, u8 port_num,
 				  struct ib_port_immutable *immutable)
 {
@@ -342,6 +340,7 @@
 
 	return 0;
 }
+#endif /* CONFIG_RVT_GET_PORT_IMMUTABLE */
 
 enum {
 	MISC,
@@ -477,9 +476,11 @@
 		break;
 
 	case GET_PORT_IMMUTABLE:
+#ifdef CONFIG_RVT_GET_PORT_IMMUTABLE
 		check_driver_override(rdi, offsetof(struct ib_device,
 						    get_port_immutable),
 				      rvt_get_port_immutable);
+#endif /* CONFIG_RVT_GET_PORT_IMMUTABLE */
 		break;
 
 	case CREATE_QP:
@@ -636,14 +637,16 @@
 
 	case ALLOC_MR:
 		check_driver_override(rdi, offsetof(struct ib_device,
-						    alloc_mr),
+						    create_mr),
 				      rvt_alloc_mr);
 		break;
 
 	case MAP_MR_SG:
+#ifdef CONFIG_RVT_MAP_MR_SG
 		check_driver_override(rdi, offsetof(struct ib_device,
 						    map_mr_sg),
 				      rvt_map_mr_sg);
+#endif /* CONFIG_RVT_MAP_MR_SG */
 		break;
 
 	case MAP_PHYS_FMR:
--- a/rdmavt/vt.h
+++ b/rdmavt/vt.h
@@ -74,7 +74,13 @@
 		      fmt, \
 		      ##__VA_ARGS__)
 
-#define rvt_pr_err(rdi, fmt, ...) \
+#define rvt_pr_warn_ratelimited(rdi, fmt, ...) \
+	__rvt_pr_warn_ratelimited(rdi->driver_f.get_pci_dev(rdi), \
+		      rdi->driver_f.get_card_name(rdi), \
+		      fmt, \
+		      ##__VA_ARGS__)
+
+#define rvt_pr_err(rdi, fmt, ...)				 \
 	__rvt_pr_err(rdi->driver_f.get_pci_dev(rdi), \
 		     rdi->driver_f.get_card_name(rdi), \
 		     fmt, \
@@ -86,6 +92,9 @@
 #define __rvt_pr_warn(pdev, name, fmt, ...) \
 	dev_warn(&pdev->dev, "%s: " fmt, name, ##__VA_ARGS__)
 
+#define __rvt_pr_warn_ratelimited(pdev, name, fmt, ...)				\
+	dev_warn_ratelimited(&pdev->dev, "%s: " fmt, name, ##__VA_ARGS__)
+
 #define __rvt_pr_err(pdev, name, fmt, ...) \
 	dev_err(&pdev->dev, "%s: " fmt, name, ##__VA_ARGS__)
 
--- a/rdmavt/mad.h
+++ b/rdmavt/mad.h
@@ -49,6 +49,7 @@
  */
 
 #include <rdma/rdma_vt.h>
+#include <rdma/ib_mad.h>
 
 int rvt_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
 		    const struct ib_wc *in_wc, const struct ib_grh *in_grh,
--- a/rdmavt/cq.c
+++ b/rdmavt/cq.c
@@ -170,7 +170,7 @@
 /**
  * rvt_create_cq - create a completion queue
  * @ibdev: the device this completion queue is attached to
- * @attr: creation attributes
+ * @entries: the minimum size of the completion queue
  * @context: unused by the QLogic_IB driver
  * @udata: user data for libibverbs.so
  *
@@ -179,20 +179,16 @@
  * Return: pointer to the completion queue or negative errno values
  * for failure.
  */
-struct ib_cq *rvt_create_cq(struct ib_device *ibdev,
-			    const struct ib_cq_init_attr *attr,
-			    struct ib_ucontext *context,
-			    struct ib_udata *udata)
+struct ib_cq *rvt_create_cq(struct ib_device *ibdev, int entries,
+							int comp_vector,
+							struct ib_ucontext *context,
+							struct ib_udata *udata)
 {
 	struct rvt_dev_info *rdi = ib_to_rvt(ibdev);
 	struct rvt_cq *cq;
 	struct rvt_cq_wc *wc;
 	struct ib_cq *ret;
 	u32 sz;
-	unsigned int entries = attr->cqe;
-
-	if (attr->flags)
-		return ERR_PTR(-EINVAL);
 
 	if (entries < 1 || entries > rdi->dparms.props.max_cqe)
 		return ERR_PTR(-EINVAL);
@@ -244,6 +240,8 @@
 	spin_lock_irq(&rdi->n_cqs_lock);
 	if (rdi->n_cqs_allocated == rdi->dparms.props.max_cq) {
 		spin_unlock_irq(&rdi->n_cqs_lock);
+		rvt_pr_warn_ratelimited(rdi, "%s: too many CQs allocated, max_cqs=%d\n",
+								__func__, rdi->dparms.props.max_cq);
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_ip;
 	}
--- a/include/rdma/rdmavt_qp.h
+++ b/include/rdma/rdmavt_qp.h
@@ -153,6 +153,81 @@
 	(RVT_PROCESS_SEND_OK | RVT_FLUSH_SEND | RVT_PROCESS_RECV_OK)
 
 /*
+ * For back porting from kernel 4.6 to Debian 8.
+ * Copied from include/rdma/ib_verbs.h.
+ */
+struct ib_send_wr_hdr {
+	struct ib_send_wr      *next;
+	u64                     wr_id;
+	struct ib_sge          *sg_list;
+	int                     num_sge;
+	enum ib_wr_opcode       opcode;
+	int                     send_flags;
+	union {
+		__be32          imm_data;
+		u32             invalidate_rkey;
+	} ex;
+};
+
+struct ib_rdma_wr {
+	struct ib_send_wr_hdr   wr;
+	u64                     remote_addr;
+	u32                     rkey;
+};
+
+static inline struct ib_rdma_wr *rdma_wr(struct ib_send_wr *wr)
+{
+	return container_of((struct ib_send_wr_hdr *)wr, struct ib_rdma_wr,
+			    wr);
+}
+
+struct ib_atomic_wr {
+	struct ib_send_wr_hdr   wr;
+	u64                     remote_addr;
+	u64                     compare_add;
+	u64                     swap;
+	u64                     compare_add_mask;
+	u64                     swap_mask;
+	u32                     rkey;
+};
+
+static inline struct ib_atomic_wr *atomic_wr(struct ib_send_wr *wr)
+{
+	return container_of((struct ib_send_wr_hdr *)wr, struct ib_atomic_wr,
+			    wr);
+}
+
+struct ib_ud_wr {
+	struct ib_send_wr_hdr   wr;
+	struct ib_ah            *ah;
+	void                    *header;
+	int                     hlen;
+	int                     mss;
+	u32                     remote_qpn;
+	u32                     remote_qkey;
+	u16                     pkey_index;
+	u8                      port_num;
+};
+
+static inline struct ib_ud_wr *ud_wr(struct ib_send_wr *wr)
+{
+	return container_of((struct ib_send_wr_hdr *)wr, struct ib_ud_wr, wr);
+}
+
+struct ib_reg_wr {
+	struct ib_send_wr_hdr   wr;
+	struct ib_mr            *mr;
+	u32                     key;
+	int                     access;
+};
+
+static inline struct ib_reg_wr *reg_wr(struct ib_send_wr *wr)
+{
+	return container_of((struct ib_send_wr_hdr *)wr, struct ib_reg_wr, wr);
+}
+
+
+/*
  * Internal send flags
  */
 #define RVT_SEND_RESERVE_USED           IB_SEND_RESERVED_START
@@ -250,6 +325,10 @@
 
 #define RVT_OPERATION_MAX (IB_WR_RESERVED10 + 1)
 
+/* Needed for Debian 8 backport */
+#define IB_WR_REG_MR IB_WR_FAST_REG_MR
+#define IB_WC_REG_MR IB_WC_FAST_REG_MR
+
 /**
  * rvt_operation_params - op table entry
  * @length - the length to copy into the swqe entry
--- a/include/rdma/rdma_vt.h
+++ b/include/rdma/rdma_vt.h
@@ -61,6 +61,9 @@
 #include <rdma/rdmavt_mr.h>
 #include <rdma/rdmavt_qp.h>
 
+/* For backporting to Debian 8 */
+#define IB_MULTICAST_LID_BASE  cpu_to_be16(0xC000)
+
 #define RVT_MAX_PKEY_VALUES 16
 
 /* For backport */
--- a/rdmavt/mr.h
+++ b/rdmavt/mr.h
@@ -49,6 +49,14 @@
  */
 
 #include <rdma/rdma_vt.h>
+
+/* For backport from kernel 4.x to Debian 8. */
+enum ib_mr_type {
+	IB_MR_TYPE_MEM_REG,
+	IB_MR_TYPE_SIGNATURE,
+	IB_MR_TYPE_SG_GAPS,
+};
+
 struct rvt_fmr {
 	struct ib_fmr ibfmr;
 	struct rvt_mregion mr;        /* must be last */
